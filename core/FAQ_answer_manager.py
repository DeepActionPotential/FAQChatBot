

from schemas.general_schemas import VectorDatabase, LLMAPIManager
from services.IO_manager import IOManager


from utils.utils import chunk_text, filter_json

class FAQAnswerManager:
    """
    Manages FAQ answers using a vector database and LLM API manager.
    """

    def __init__(
        self,
        Faiss_vecotr_database: VectorDatabase,
        llm_api_manager: LLMAPIManager,
        io_manager: IOManager,
        logger
    ):
        """
        Initializes the FAQAnswerManager.

        :param Faiss_vecotr_database: An instance of VectorDatabase for storing and searching text vectors.
        :param llm_api_manager: An instance of LLMAPIManager for interacting with the language model API.
        :param io_manager: An object responsible for input/output operations (e.g., loading files).
        :param logger: Logger instance for logging information and errors.
        """
        self.Faiss_vecotr_database = Faiss_vecotr_database
        self.llm_api_manager = llm_api_manager
        self.io_manager = io_manager
        self.logger = logger
    

    def load_text_into_faiss(self, file_path: str, n_char:int, overlap:int) -> None:
        """
        Loads text from a file into the Faiss vector database.

        :param file_path: Path to the text file to be loaded.
        :param n_char: Number of characters per text chunk.
        :param overlap: Number of overlapping characters between chunks.
        """

        try:

            text = self.io_manager.load(file_path)
            texts = chunk_text(text, n_char, overlap)
            self.Faiss_vecotr_database.add_texts(texts)
            self.logger.info(f"Successfully loaded text from {file_path} into Faiss.")

        except Exception as e:
            self.logger.error(f"Failed to load text from {file_path}: {e}")
    

    def save_faiss_index(self, index_path: str) -> None:
        """
        Saves the Faiss index and associated text metadata.

        :param index_path: Path to save the Faiss index.
        :param metadata_path: Path to save the text metadata.
        """
        self.Faiss_vecotr_database.save_index(index_path)
    

    def load_faiss_index(self, index_path: str) -> None:
        """
        Loads the Faiss index and associated text metadata.

        :param index_path: Path to load the Faiss index from.
        :param metadata_path: Path to load the text metadata from.
        """
        self.Faiss_vecotr_database.load_index(index_path)
    

    def clear_faiss_index(self) -> None:
        """
        Clears the Faiss index and associated text metadata.
        """
        self.Faiss_vecotr_database.clear_index()
    

    def get_answers(
        self,
        question: str,
        FAQ_answer_prompt: str,
        top_k: int = 10,
        n_answers: int = 2
    ) -> list:
        """
        Retrieves answers to a given question from the FAQ source.

        :param answers_source_path: Path to the source file containing FAQ answers.
        :param question: The question to search for.
        :param FAQ_answer_prompt: Prompt template for the LLM.
        :param n_char: Number of characters per text chunk.
        :param overlap: Number of overlapping characters between chunks.
        :param top_k: Number of top search results to retrieve from the vector database.
        :param n_answers: Number of answers to generate.
        :return: A list of filtered answers generated by the LLM.
        """
        
        searches = self.Faiss_vecotr_database.search(question, top_k=top_k)
        final_prompt = FAQ_answer_prompt.format(
            question=question,
            search_results=searches,
            n_answers=n_answers
        )
        json_content = self.llm_api_manager.send_prompt(final_prompt)
        print(filter_json(json_content))
        return filter_json(json_content)